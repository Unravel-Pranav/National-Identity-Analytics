{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç Aadhaar Data Analysis - Novel EDA\n",
        "## Discovering Unique Identity Lifecycle Patterns at Micro-Geographic Level\n",
        "\n",
        "**Datasets:**\n",
        "- Biometric Updates (1.86M records)\n",
        "- Demographic Updates (2.07M records)  \n",
        "- Enrolment Data (1M records)\n",
        "\n",
        "**Novel Approach:** Analyzing identity system behavior at pincode granularity to discover:\n",
        "1. Identity Lifecycle Velocity (how fast identity data changes)\n",
        "2. Biometric Stress Patterns (regions with high biometric update needs)\n",
        "3. Demographic Volatility Index (address/name change patterns)\n",
        "4. Age-cohort specific identity behaviors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Initial Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all datasets\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Biometric data\n",
        "bio_files = glob.glob('data/api_data_aadhar_biometric/*.csv')\n",
        "bio_df = pd.concat([pd.read_csv(f) for f in bio_files], ignore_index=True)\n",
        "\n",
        "# Demographic data\n",
        "demo_files = glob.glob('data/api_data_aadhar_demographic/*.csv')\n",
        "demo_df = pd.concat([pd.read_csv(f) for f in demo_files], ignore_index=True)\n",
        "\n",
        "# Enrolment data\n",
        "enrol_files = glob.glob('data/api_data_aadhar_enrolment/*.csv')\n",
        "enrol_df = pd.concat([pd.read_csv(f) for f in enrol_files], ignore_index=True)\n",
        "\n",
        "print(f\"Biometric: {bio_df.shape}\")\n",
        "print(f\"Demographic: {demo_df.shape}\")\n",
        "print(f\"Enrolment: {enrol_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample data\n",
        "print(\"\\n=== BIOMETRIC DATA ===\")\n",
        "display(bio_df.head())\n",
        "\n",
        "print(\"\\n=== DEMOGRAPHIC DATA ===\")\n",
        "display(demo_df.head())\n",
        "\n",
        "print(\"\\n=== ENROLMENT DATA ===\")\n",
        "display(enrol_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Analysis & Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# State name standardization mapping\n",
        "STATE_MAPPING = {\n",
        "    # West Bengal variations\n",
        "    'WEST BENGAL': 'West Bengal', 'WESTBENGAL': 'West Bengal', 'West  Bengal': 'West Bengal',\n",
        "    'West Bangal': 'West Bengal', 'West Bengli': 'West Bengal', 'Westbengal': 'West Bengal',\n",
        "    'west Bengal': 'West Bengal',\n",
        "    # Odisha variations\n",
        "    'ODISHA': 'Odisha', 'Orissa': 'Odisha', 'odisha': 'Odisha',\n",
        "    # Others\n",
        "    'andhra pradesh': 'Andhra Pradesh', 'Tamilnadu': 'Tamil Nadu',\n",
        "    'Jammu & Kashmir': 'Jammu and Kashmir', 'Jammu And Kashmir': 'Jammu and Kashmir',\n",
        "    'Chhatisgarh': 'Chhattisgarh', 'Uttaranchal': 'Uttarakhand', 'Pondicherry': 'Puducherry',\n",
        "    'Andaman & Nicobar Islands': 'Andaman and Nicobar Islands',\n",
        "    'Dadra & Nagar Haveli': 'Dadra and Nagar Haveli and Daman and Diu',\n",
        "    'Dadra and Nagar Haveli': 'Dadra and Nagar Haveli and Daman and Diu',\n",
        "    'Daman & Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
        "    'Daman and Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
        "    'The Dadra And Nagar Haveli And Daman And Diu': 'Dadra and Nagar Haveli and Daman and Diu',\n",
        "}\n",
        "\n",
        "# Invalid state entries (data entry errors)\n",
        "INVALID_STATES = ['100000', 'BALANAGAR', 'Darbhanga', 'Jaipur', 'Madanapalle', \n",
        "                  'Nagpur', 'Puttenahalli', 'Raja Annamalai Puram']\n",
        "\n",
        "def clean_state_name(df):\n",
        "    \"\"\"Standardize state names and remove invalid entries\"\"\"\n",
        "    df = df.copy()\n",
        "    df['state'] = df['state'].replace(STATE_MAPPING)\n",
        "    df = df[~df['state'].isin(INVALID_STATES)]\n",
        "    return df\n",
        "\n",
        "# Apply cleaning\n",
        "bio_df = clean_state_name(bio_df)\n",
        "demo_df = clean_state_name(demo_df)\n",
        "enrol_df = clean_state_name(enrol_df)\n",
        "\n",
        "# Convert date columns to datetime\n",
        "bio_df['date'] = pd.to_datetime(bio_df['date'], format='%d-%m-%Y')\n",
        "demo_df['date'] = pd.to_datetime(demo_df['date'], format='%d-%m-%Y')\n",
        "enrol_df['date'] = pd.to_datetime(enrol_df['date'], format='%d-%m-%Y')\n",
        "\n",
        "# Add derived time columns\n",
        "for df in [bio_df, demo_df, enrol_df]:\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['month_year'] = df['date'].dt.to_period('M')\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek\n",
        "\n",
        "print(f\"After cleaning:\")\n",
        "print(f\"  Biometric: {bio_df.shape}\")\n",
        "print(f\"  Demographic: {demo_df.shape}\")\n",
        "print(f\"  Enrolment: {enrol_df.shape}\")\n",
        "print(f\"\\nUnique states: {bio_df['state'].nunique()}\")\n",
        "print(f\"Date range: {bio_df['date'].min()} to {bio_df['date'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering - Novel Identity Lifecycle Metrics\n",
        "\n",
        "**Creating unique derived metrics not seen in standard Aadhaar analyses:**\n",
        "- **Identity Velocity Index (IVI)**: Updates per capita - measures identity data volatility\n",
        "- **Biometric Stress Index (BSI)**: Bio/Demo ratio - indicates biometric-related issues\n",
        "- **Youth Update Intensity**: Age-group specific patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add total columns\n",
        "bio_df['total_bio_updates'] = bio_df['bio_age_5_17'] + bio_df['bio_age_17_']\n",
        "demo_df['total_demo_updates'] = demo_df['demo_age_5_17'] + demo_df['demo_age_17_']\n",
        "enrol_df['total_enrolments'] = enrol_df['age_0_5'] + enrol_df['age_5_17'] + enrol_df['age_18_greater']\n",
        "\n",
        "# Age group ratios\n",
        "bio_df['youth_ratio_bio'] = bio_df['bio_age_5_17'] / (bio_df['total_bio_updates'] + 1)\n",
        "demo_df['youth_ratio_demo'] = demo_df['demo_age_5_17'] / (demo_df['total_demo_updates'] + 1)\n",
        "enrol_df['infant_ratio'] = enrol_df['age_0_5'] / (enrol_df['total_enrolments'] + 1)\n",
        "\n",
        "print(\"Added derived columns to all dataframes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. NOVEL ANALYSIS 1: Pincode-Level Identity Velocity Index\n",
        "\n",
        "**Concept:** Measure how \"dynamic\" identity data is at each pincode by combining biometric & demographic update rates normalized by enrolment base.\n",
        "\n",
        "This creates an **Identity Velocity Score** - higher means more identity changes per capita\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate by pincode\n",
        "bio_pincode = bio_df.groupby(['pincode', 'state', 'district']).agg({\n",
        "    'bio_age_5_17': 'sum', 'bio_age_17_': 'sum', 'total_bio_updates': 'sum',\n",
        "    'date': 'count'\n",
        "}).rename(columns={'date': 'bio_records'}).reset_index()\n",
        "\n",
        "demo_pincode = demo_df.groupby(['pincode', 'state', 'district']).agg({\n",
        "    'demo_age_5_17': 'sum', 'demo_age_17_': 'sum', 'total_demo_updates': 'sum',\n",
        "    'date': 'count'\n",
        "}).rename(columns={'date': 'demo_records'}).reset_index()\n",
        "\n",
        "enrol_pincode = enrol_df.groupby(['pincode', 'state', 'district']).agg({\n",
        "    'age_0_5': 'sum', 'age_5_17': 'sum', 'age_18_greater': 'sum',\n",
        "    'total_enrolments': 'sum', 'date': 'count'\n",
        "}).rename(columns={'date': 'enrol_records'}).reset_index()\n",
        "\n",
        "print(f\"Unique pincodes - Bio: {len(bio_pincode)}, Demo: {len(demo_pincode)}, Enrol: {len(enrol_pincode)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all three datasets at pincode level\n",
        "pincode_merged = bio_pincode.merge(\n",
        "    demo_pincode[['pincode', 'demo_age_5_17', 'demo_age_17_', 'total_demo_updates']], \n",
        "    on='pincode', how='outer'\n",
        ").merge(\n",
        "    enrol_pincode[['pincode', 'age_0_5', 'age_5_17', 'age_18_greater', 'total_enrolments']], \n",
        "    on='pincode', how='outer'\n",
        ")\n",
        "\n",
        "pincode_merged = pincode_merged.fillna(0)\n",
        "\n",
        "# Calculate Identity Velocity Index (IVI)\n",
        "pincode_merged['total_updates'] = pincode_merged['total_bio_updates'] + pincode_merged['total_demo_updates']\n",
        "pincode_merged['identity_velocity_index'] = (\n",
        "    pincode_merged['total_updates'] / (pincode_merged['total_enrolments'] + 1)\n",
        ") * 100\n",
        "\n",
        "# Biometric Stress Index (BSI)\n",
        "pincode_merged['biometric_stress_index'] = (\n",
        "    pincode_merged['total_bio_updates'] / (pincode_merged['total_demo_updates'] + 1)\n",
        ")\n",
        "\n",
        "# Youth Update Intensity\n",
        "pincode_merged['youth_update_ratio'] = (\n",
        "    (pincode_merged['bio_age_5_17'] + pincode_merged['demo_age_5_17']) / \n",
        "    (pincode_merged['total_updates'] + 1)\n",
        ")\n",
        "\n",
        "print(f\"Merged dataset shape: {pincode_merged.shape}\")\n",
        "print(\"\\nNovel Indices Statistics:\")\n",
        "print(pincode_merged[['identity_velocity_index', 'biometric_stress_index', 'youth_update_ratio']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Identity Velocity Index Distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "# IVI Distribution\n",
        "ax1 = axes[0]\n",
        "data_ivi = pincode_merged['identity_velocity_index']\n",
        "data_ivi_clipped = data_ivi[data_ivi < data_ivi.quantile(0.99)]  # Remove outliers\n",
        "ax1.hist(data_ivi_clipped, bins=50, color='#2E86AB', edgecolor='white', alpha=0.8)\n",
        "ax1.set_xlabel('Identity Velocity Index')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_title('Distribution of Identity Velocity Index\\n(Updates per Enrolment)')\n",
        "ax1.axvline(data_ivi_clipped.median(), color='red', linestyle='--', label=f'Median: {data_ivi_clipped.median():.1f}')\n",
        "ax1.legend()\n",
        "\n",
        "# BSI Distribution\n",
        "ax2 = axes[1]\n",
        "data_bsi = pincode_merged['biometric_stress_index']\n",
        "data_bsi_clipped = data_bsi[data_bsi < data_bsi.quantile(0.99)]\n",
        "ax2.hist(data_bsi_clipped, bins=50, color='#E94F37', edgecolor='white', alpha=0.8)\n",
        "ax2.set_xlabel('Biometric Stress Index')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.set_title('Distribution of Biometric Stress Index\\n(Bio/Demo Update Ratio)')\n",
        "ax2.axvline(data_bsi_clipped.median(), color='blue', linestyle='--', label=f'Median: {data_bsi_clipped.median():.2f}')\n",
        "ax2.legend()\n",
        "\n",
        "# Youth Update Ratio\n",
        "ax3 = axes[2]\n",
        "ax3.hist(pincode_merged['youth_update_ratio'], bins=50, color='#44AF69', edgecolor='white', alpha=0.8)\n",
        "ax3.set_xlabel('Youth Update Ratio')\n",
        "ax3.set_ylabel('Frequency')\n",
        "ax3.set_title('Distribution of Youth Update Ratio\\n(5-17 Age Group Share)')\n",
        "ax3.axvline(pincode_merged['youth_update_ratio'].median(), color='red', linestyle='--', \n",
        "            label=f'Median: {pincode_merged[\"youth_update_ratio\"].median():.2f}')\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('identity_indices_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. NOVEL ANALYSIS 2: State-Level Identity Behavior Profiling\n",
        "\n",
        "**Concept:** Profile states based on identity update patterns to identify:\n",
        "- High-stress states (need biometric alternatives like iris/OTP)\n",
        "- High-volatility states (need better document verification)\n",
        "- Stable states (best practices to replicate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate by state\n",
        "state_bio = bio_df.groupby('state').agg({\n",
        "    'bio_age_5_17': 'sum', 'bio_age_17_': 'sum', 'total_bio_updates': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "state_demo = demo_df.groupby('state').agg({\n",
        "    'demo_age_5_17': 'sum', 'demo_age_17_': 'sum', 'total_demo_updates': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "state_enrol = enrol_df.groupby('state').agg({\n",
        "    'age_0_5': 'sum', 'age_5_17': 'sum', 'age_18_greater': 'sum', 'total_enrolments': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Merge\n",
        "state_merged = state_bio.merge(state_demo, on='state').merge(state_enrol, on='state')\n",
        "\n",
        "# Calculate state-level indices\n",
        "state_merged['total_updates'] = state_merged['total_bio_updates'] + state_merged['total_demo_updates']\n",
        "state_merged['IVI'] = state_merged['total_updates'] / (state_merged['total_enrolments'] + 1) * 100\n",
        "state_merged['BSI'] = state_merged['total_bio_updates'] / (state_merged['total_demo_updates'] + 1)\n",
        "state_merged['youth_ratio'] = (\n",
        "    (state_merged['bio_age_5_17'] + state_merged['demo_age_5_17']) / \n",
        "    (state_merged['total_updates'] + 1)\n",
        ")\n",
        "\n",
        "print(f\"State-level data: {state_merged.shape}\")\n",
        "state_merged.sort_values('total_updates', ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize State-wise comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Top 15 states by total updates\n",
        "top_states = state_merged.nlargest(15, 'total_updates')\n",
        "\n",
        "# 1. Total Updates by State\n",
        "ax1 = axes[0, 0]\n",
        "colors = plt.cm.viridis(np.linspace(0, 0.8, len(top_states)))\n",
        "ax1.barh(top_states['state'], top_states['total_updates']/1e6, color=colors)\n",
        "ax1.set_xlabel('Total Updates (Millions)')\n",
        "ax1.set_title('Top 15 States by Total Identity Updates', fontweight='bold')\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# 2. Biometric vs Demographic Updates\n",
        "ax2 = axes[0, 1]\n",
        "x = np.arange(len(top_states))\n",
        "width = 0.35\n",
        "ax2.barh(x - width/2, top_states['total_bio_updates']/1e6, width, label='Biometric', color='#2E86AB')\n",
        "ax2.barh(x + width/2, top_states['total_demo_updates']/1e6, width, label='Demographic', color='#E94F37')\n",
        "ax2.set_yticks(x)\n",
        "ax2.set_yticklabels(top_states['state'])\n",
        "ax2.set_xlabel('Updates (Millions)')\n",
        "ax2.set_title('Biometric vs Demographic Updates', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "# 3. Identity Velocity Index\n",
        "ax3 = axes[1, 0]\n",
        "state_sorted_ivi = state_merged.nlargest(15, 'IVI')\n",
        "colors_ivi = ['#E94F37' if x > state_merged['IVI'].median() else '#44AF69' for x in state_sorted_ivi['IVI']]\n",
        "ax3.barh(state_sorted_ivi['state'], state_sorted_ivi['IVI'], color=colors_ivi)\n",
        "ax3.set_xlabel('Identity Velocity Index')\n",
        "ax3.set_title('Top 15 States by Identity Velocity Index\\n(Higher = More Updates per Enrolment)', fontweight='bold')\n",
        "ax3.invert_yaxis()\n",
        "\n",
        "# 4. Biometric Stress Index\n",
        "ax4 = axes[1, 1]\n",
        "state_sorted_bsi = state_merged.nlargest(15, 'BSI')\n",
        "colors_bsi = plt.cm.Reds(np.linspace(0.3, 0.9, len(state_sorted_bsi)))\n",
        "ax4.barh(state_sorted_bsi['state'], state_sorted_bsi['BSI'], color=colors_bsi)\n",
        "ax4.set_xlabel('Biometric Stress Index')\n",
        "ax4.set_title('Top 15 States by Biometric Stress Index\\n(Higher = More Bio Updates vs Demo)', fontweight='bold')\n",
        "ax4.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('state_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. NOVEL ANALYSIS 3: Temporal Patterns Discovery\n",
        "\n",
        "**Concept:** Discover operational patterns in Aadhaar updates:\n",
        "- Which days see most activity? (Operational planning)\n",
        "- Weekly seasonality (Resource allocation)\n",
        "- Month-end surge patterns (Administrative deadline effects)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day-of-week analysis\n",
        "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "bio_by_day = bio_df.groupby('day_of_week')['total_bio_updates'].sum()\n",
        "demo_by_day = demo_df.groupby('day_of_week')['total_demo_updates'].sum()\n",
        "enrol_by_day = enrol_df.groupby('day_of_week')['total_enrolments'].sum()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "# Biometric by day\n",
        "ax1 = axes[0]\n",
        "ax1.bar([day_names[i] for i in bio_by_day.index], bio_by_day.values/1e6, color='#2E86AB')\n",
        "ax1.set_ylabel('Updates (Millions)')\n",
        "ax1.set_title('Biometric Updates by Day of Week', fontweight='bold')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Demographic by day\n",
        "ax2 = axes[1]\n",
        "ax2.bar([day_names[i] for i in demo_by_day.index], demo_by_day.values/1e6, color='#E94F37')\n",
        "ax2.set_ylabel('Updates (Millions)')\n",
        "ax2.set_title('Demographic Updates by Day of Week', fontweight='bold')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Enrolments by day\n",
        "ax3 = axes[2]\n",
        "ax3.bar([day_names[i] for i in enrol_by_day.index], enrol_by_day.values/1e6, color='#44AF69')\n",
        "ax3.set_ylabel('Enrolments (Millions)')\n",
        "ax3.set_title('New Enrolments by Day of Week', fontweight='bold')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('day_of_week_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series - Monthly trends\n",
        "bio_monthly = bio_df.groupby('month_year')['total_bio_updates'].sum()\n",
        "demo_monthly = demo_df.groupby('month_year')['total_demo_updates'].sum()\n",
        "enrol_monthly = enrol_df.groupby('month_year')['total_enrolments'].sum()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "x_bio = [str(x) for x in bio_monthly.index]\n",
        "x_demo = [str(x) for x in demo_monthly.index]\n",
        "x_enrol = [str(x) for x in enrol_monthly.index]\n",
        "\n",
        "ax.plot(x_bio, bio_monthly.values/1e6, marker='o', linewidth=2, label='Biometric Updates', color='#2E86AB')\n",
        "ax.plot(x_demo, demo_monthly.values/1e6, marker='s', linewidth=2, label='Demographic Updates', color='#E94F37')\n",
        "ax.plot(x_enrol, enrol_monthly.values/1e6, marker='^', linewidth=2, label='New Enrolments', color='#44AF69')\n",
        "\n",
        "ax.set_xlabel('Month-Year')\n",
        "ax.set_ylabel('Count (Millions)')\n",
        "ax.set_title('Monthly Trends in Aadhaar Activity', fontweight='bold', fontsize=14)\n",
        "ax.legend()\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('monthly_trends.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. NOVEL ANALYSIS 4: Correlation Analysis - Biometric vs Demographic\n",
        "\n",
        "**Key Question:** Do areas with high biometric updates also have high demographic updates, or are they inversely related?\n",
        "\n",
        "This reveals whether identity maintenance patterns are uniform or specialized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation at pincode level\n",
        "correlation_data = pincode_merged[['total_bio_updates', 'total_demo_updates', 'total_enrolments', \n",
        "                                   'bio_age_5_17', 'bio_age_17_', 'demo_age_5_17', 'demo_age_17_',\n",
        "                                   'age_0_5', 'age_5_17', 'age_18_greater']].copy()\n",
        "\n",
        "correlation_data.columns = ['Bio Total', 'Demo Total', 'Enrol Total',\n",
        "                            'Bio 5-17', 'Bio 17+', 'Demo 5-17', 'Demo 17+',\n",
        "                            'Enrol 0-5', 'Enrol 5-17', 'Enrol 18+']\n",
        "\n",
        "corr_matrix = correlation_data.corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
        "            square=True, linewidths=0.5, ax=ax, vmin=-1, vmax=1)\n",
        "ax.set_title('Correlation Matrix: Pincode-Level Activity Metrics', fontweight='bold', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Correlations:\")\n",
        "print(f\"Bio Total vs Demo Total: {corr_matrix.loc['Bio Total', 'Demo Total']:.3f}\")\n",
        "print(f\"Bio Total vs Enrol Total: {corr_matrix.loc['Bio Total', 'Enrol Total']:.3f}\")\n",
        "print(f\"Demo Total vs Enrol Total: {corr_matrix.loc['Demo Total', 'Enrol Total']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Statistics & Key Findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"                    KEY FINDINGS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìä DATASET OVERVIEW:\")\n",
        "print(f\"   ‚Ä¢ Total Biometric Updates: {bio_df['total_bio_updates'].sum():,.0f}\")\n",
        "print(f\"   ‚Ä¢ Total Demographic Updates: {demo_df['total_demo_updates'].sum():,.0f}\")\n",
        "print(f\"   ‚Ä¢ Total New Enrolments: {enrol_df['total_enrolments'].sum():,.0f}\")\n",
        "print(f\"   ‚Ä¢ Unique Pincodes Covered: {pincode_merged['pincode'].nunique():,}\")\n",
        "print(f\"   ‚Ä¢ States/UTs Covered: {bio_df['state'].nunique()}\")\n",
        "\n",
        "print(\"\\nüîç NOVEL INDICES COMPUTED:\")\n",
        "print(f\"   ‚Ä¢ Identity Velocity Index (IVI)\")\n",
        "print(f\"     - Median: {pincode_merged['identity_velocity_index'].median():.2f}\")\n",
        "print(f\"     - Max: {pincode_merged['identity_velocity_index'].max():.2f}\")\n",
        "print(f\"   ‚Ä¢ Biometric Stress Index (BSI)\")\n",
        "print(f\"     - Median: {pincode_merged['biometric_stress_index'].median():.2f}\")\n",
        "print(f\"     - Max: {pincode_merged['biometric_stress_index'].max():.2f}\")\n",
        "\n",
        "print(\"\\nüèÜ TOP STATES BY ACTIVITY:\")\n",
        "top3 = state_merged.nlargest(3, 'total_updates')\n",
        "for i, row in enumerate(top3.itertuples(), 1):\n",
        "    print(f\"   {i}. {row.state}: {row.total_updates:,.0f} total updates\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è HIGH BIOMETRIC STRESS STATES:\")\n",
        "high_bsi = state_merged.nlargest(3, 'BSI')\n",
        "for i, row in enumerate(high_bsi.itertuples(), 1):\n",
        "    print(f\"   {i}. {row.state}: BSI = {row.BSI:.2f}\")\n",
        "\n",
        "total_updates = bio_df['total_bio_updates'].sum() + demo_df['total_demo_updates'].sum()\n",
        "youth_updates = bio_df['bio_age_5_17'].sum() + demo_df['demo_age_5_17'].sum()\n",
        "adult_updates = bio_df['bio_age_17_'].sum() + demo_df['demo_age_17_'].sum()\n",
        "\n",
        "print(\"\\nüìà AGE GROUP INSIGHTS:\")\n",
        "print(f\"   ‚Ä¢ Youth (5-17) share of updates: {youth_updates / total_updates * 100:.1f}%\")\n",
        "print(f\"   ‚Ä¢ Adult (17+) share of updates: {adult_updates / total_updates * 100:.1f}%\")\n",
        "print(f\"   ‚Ä¢ Infant (0-5) enrolments: {enrol_df['age_0_5'].sum():,.0f} ({enrol_df['age_0_5'].sum() / enrol_df['total_enrolments'].sum() * 100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ NOVEL IDEAS FOR DEEPER ANALYSIS & ML\n",
        "\n",
        "Based on EDA, here are **truly unique and feasible** approaches not commonly seen:\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 1: **Pincode-Level Identity Lifecycle Scoring System**\n",
        "**What:** Create a composite score for each pincode that predicts future update load\n",
        "**Novel aspect:** No existing Aadhaar analysis does micro-geographic prediction\n",
        "**Use:** Resource allocation for enrolment centers\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 2: **Age-Cohort Biometric Degradation Model**\n",
        "**What:** Track how biometric update rates change across age groups over time\n",
        "**Novel aspect:** Quantify \"biometric aging\" at population level\n",
        "**Use:** Plan for iris/OTP fallback in specific demographics\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 3: **State Identity Stability Ranking**\n",
        "**What:** Rank states by identity data stability using IVI, BSI, and update patterns\n",
        "**Novel aspect:** Creates actionable policy-ready rankings\n",
        "**Use:** Identify states needing intervention vs best-practice states\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 4: **Temporal Anomaly Detection System**\n",
        "**What:** ML model to detect unusual update spikes at pincode level\n",
        "**Novel aspect:** Real-time operational intelligence\n",
        "**Use:** Early warning system for data quality issues\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 5: **Youth Identity Trajectory Prediction**\n",
        "**What:** Predict when youth (5-17) will need updates based on patterns\n",
        "**Novel aspect:** Proactive service delivery instead of reactive\n",
        "**Use:** Send notifications before mandatory updates\n",
        "\n",
        "---\n",
        "\n",
        "### üî• IDEA 6: **Cross-Dataset Coherence Analysis**\n",
        "**What:** Check if enrolment patterns match update patterns (logical consistency)\n",
        "**Novel aspect:** Data quality validation at scale\n",
        "**Use:** Identify regions with data integrity issues\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
